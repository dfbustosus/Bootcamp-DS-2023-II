{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalacion\n",
    "\n",
    "Tutorial: https://www.youtube.com/watch?v=WxWRXNna1Qw&ab_channel=coder2j\n",
    "\n",
    "Se necesita Java JDK, Python y Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark\n",
    "#!pip install findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tengo Python 3.9 las instalaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['SPARK_HOME']=r'C:/spark/'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']='jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='lab'\n",
    "os.environ['PYSPARK_PYTHON']='python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"Ejercicios SQL\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- agentid: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+-------+------------------+\n",
      "|agentid|              name|\n",
      "+-------+------------------+\n",
      "|      0|  Michele Williams|\n",
      "|      1|    Jocelyn Parker|\n",
      "|      2|Christopher Moreno|\n",
      "|      3|       Todd Morrow|\n",
      "|      4|       Randy Moore|\n",
      "|      5|        Paul Nunez|\n",
      "|      6|      Gloria Singh|\n",
      "|      7|      Angel Briggs|\n",
      "|      8|      Lisa Cordova|\n",
      "|      9|        Dana Hardy|\n",
      "|     10|           Agent X|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar data de agents.csv\n",
    "df_agents = spark.read.option(\"header\",True) \\\n",
    "        .option(\"inferSchema\",True) \\\n",
    "        .csv(\"./agents.csv\", )\n",
    "df_agents.printSchema()\n",
    "df_agents.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- callid: integer (nullable = true)\n",
      " |-- agentid: integer (nullable = true)\n",
      " |-- customerid: integer (nullable = true)\n",
      " |-- pickedup: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- productsold: integer (nullable = true)\n",
      "\n",
      "+------+-------+----------+--------+--------+-----------+\n",
      "|callid|agentid|customerid|pickedup|duration|productsold|\n",
      "+------+-------+----------+--------+--------+-----------+\n",
      "|     0|     10|       179|       0|       0|          0|\n",
      "|     1|      5|       691|       1|     116|          0|\n",
      "|     2|     10|        80|       1|     165|          0|\n",
      "|     3|      6|       629|       1|     128|          0|\n",
      "|     4|      8|       318|       1|     205|          0|\n",
      "|     5|      7|       319|       1|     225|          1|\n",
      "|     6|     10|       265|       1|     211|          0|\n",
      "|     7|      9|       625|       0|       0|          0|\n",
      "|     8|      5|       877|       0|       0|          0|\n",
      "|     9|      5|       191|       1|     145|          0|\n",
      "|    10|      9|       494|       0|       0|          0|\n",
      "|    11|      5|       558|       0|       0|          0|\n",
      "|    12|      3|       703|       1|     303|          0|\n",
      "|    13|      5|       684|       1|     258|          0|\n",
      "|    14|      2|       601|       1|     179|          0|\n",
      "|    15|     10|       399|       0|       0|          0|\n",
      "|    16|      8|       460|       0|       0|          0|\n",
      "|    17|     10|       858|       1|     118|          1|\n",
      "|    18|      4|       192|       0|       0|          0|\n",
      "|    19|      8|       413|       1|     180|          0|\n",
      "+------+-------+----------+--------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9940"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = spark.read.option(\"header\",True) \\\n",
    "        .option(\"inferSchema\",True) \\\n",
    "        .csv(\"./calls.csv\", )\n",
    "df_calls.printSchema()\n",
    "df_calls.show()\n",
    "df_calls.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerid: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      " |-- phonenumber: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      "\n",
      "+----------+------------------+--------------------+--------------------+--------------------+------------+---+\n",
      "|customerid|              name|          occupation|               email|             company| phonenumber|Age|\n",
      "+----------+------------------+--------------------+--------------------+--------------------+------------+---+\n",
      "|         0|      David Melton|          Unemployed|    DMelton@zoho.com|Morris, Winters a...|409-093-0748| 16|\n",
      "|         1|  Michael Gonzalez|             Student|Gonzalez_Michael@...|  Hernandez and Sons|231-845-0673| 19|\n",
      "|         2|     Amanda Wilson|             Student|Amanda.Wilson75@v...|Mooney, West and ...|844-276-4552| 18|\n",
      "|         3|     Robert Thomas|Engineer, structural| RThomas@xfinity.com|      Johnson-Gordon|410-404-8000| 25|\n",
      "|         4|        Eddie Hall|             Surgeon|EddieHall@outlook...|          Dawson LLC|872-287-2196| 30|\n",
      "|         5|  Charles Cruz DDS|          Unemployed|CharlesDDS55@hotm...|   Mitchell and Sons|744-564-0382| 16|\n",
      "|         6|     Maria Johnson|Engineer, aeronau...|    MJohnson@aol.com|         Gibbs-Avery|448-258-9852| 22|\n",
      "|         7|    Michael Vaughn|   Librarian, public|MichaelVaughn@zoh...|            Rice LLC|275-669-5217| 30|\n",
      "|         8|Emily Anderson DDS|           Solicitor| Emily_DDS@yahoo.com|     Little and Sons|334-290-7258| 28|\n",
      "|         9|     Travis Jensen|          Unemployed|Travis.Jensen@hot...|     Edwards-Collins|106-848-8870| 13|\n",
      "|        10|        Ryan Banks|             Student|Ryan_Banks35@gmai...|Mitchell, Dean an...|465-548-1441| 21|\n",
      "|        11| Brandon Alexander|   Chemical engineer|Alexander_Brandon...|         Robbins Ltd|305-319-8515| 29|\n",
      "|        12|     Valerie Moore|          Unemployed|Moore_Valerie@ver...|       Choi and Sons|288-680-8457| 16|\n",
      "|        13|          Tina Cox|          Unemployed|Tina_Cox@protonma...|Giles, Harris and...|535-922-1854| 16|\n",
      "|        14|    Michelle Reyes|  Engineer, drilling|Michelle.Reyes@ao...|Stewart, Dawson a...|280-280-1661| 31|\n",
      "|        15|     Grace Pearson|          Unemployed|  Grace_P@yandex.com|       Taylor-Walker|973-809-0260| 14|\n",
      "|        16|       Lauren Hill|          Counsellor|Hill_Lauren73@aol...|Parsons, Nelson a...|175-283-1682| 27|\n",
      "|        17|    Kelsey Perkins|               Nurse|  Kelsey_P80@att.com|Stephenson, Mccoy...|925-021-2855| 25|\n",
      "|        18|      Zachary Howe|          Unemployed|Howe.Zachary@xfin...|Mullins, Dawson a...|556-773-8367|  0|\n",
      "|        19|  Elizabeth Harris|          Unemployed|Elizabeth_Harris3...|Grant, Bowman and...|177-551-8499| 11|\n",
      "+----------+------------------+--------------------+--------------------+--------------------+------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar data de customers.csv\n",
    "df_customers = spark.read.option(\"header\",True) \\\n",
    "        .option(\"inferSchema\",True) \\\n",
    "        .csv(\"./customers.csv\", )\n",
    "df_customers.printSchema()\n",
    "df_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary tables\n",
    "df_agents.createOrReplaceTempView(\"agents\")       # Agentes\n",
    "df_calls.createOrReplaceTempView(\"calls\")         # Llamadas\n",
    "df_customers.createOrReplaceTempView(\"customers\") # Clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Extraer agentes cuyo nombre empiezen por M o terminen en O\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|agentid|              name|\n",
      "+-------+------------------+\n",
      "|      0|  Michele Williams|\n",
      "|      2|Christopher Moreno|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Select query\n",
    "df_ej_1 = spark.sql(\"\"\"\n",
    "select * from agents\n",
    "where name like 'M%' or name like '%o'\n",
    "\"\"\")\n",
    "df_ej_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "Escriba una consulta que produzca una lista, en orden alfabético, de todas las distintas ocupaciones en la tabla Customer que contengan la palabra \"Engineer\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          Occupation|\n",
      "+--------------------+\n",
      "|Engineer, aeronau...|\n",
      "|Engineer, agricul...|\n",
      "|Engineer, automotive|\n",
      "|Engineer, biomedical|\n",
      "|Engineer, broadca...|\n",
      "|Engineer, buildin...|\n",
      "|Engineer, civil (...|\n",
      "|Engineer, civil (...|\n",
      "|Engineer, communi...|\n",
      "|Engineer, control...|\n",
      "|  Engineer, drilling|\n",
      "|Engineer, electrical|\n",
      "|Engineer, electro...|\n",
      "|    Engineer, energy|\n",
      "|      Engineer, land|\n",
      "|Engineer, mainten...|\n",
      "|Engineer, mainten...|\n",
      "|Engineer, manufac...|\n",
      "|Engineer, manufac...|\n",
      "| Engineer, materials|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ej_2 = spark.sql(\"\"\"\n",
    "SELECT DISTINCT Occupation\n",
    "FROM customers\n",
    "WHERE Occupation LIKE '%Engineer%'\n",
    "ORDER BY Occupation\n",
    "\"\"\")\n",
    "df_ej_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3\n",
    "\n",
    "Escriba una consulta que devuelva el ID del cliente, su nombre y una columna Mayor30 que contenga \"Sí\" si el cliente tiene más de 30 años y \"No\" en caso contrario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------+\n",
      "|CustomerID|             Name|Over30|\n",
      "+----------+-----------------+------+\n",
      "|       392|   Zachary Wilson|   Yes|\n",
      "|       986|Zachary Stevenson|    No|\n",
      "|       421|     Zachary Ruiz|   Yes|\n",
      "|        18|     Zachary Howe|    No|\n",
      "|       883| Zachary Anderson|    No|\n",
      "|       952|    Yolanda White|    No|\n",
      "|       715|   Yesenia Wright|    No|\n",
      "|       699|    Willie Greene|   Yes|\n",
      "|       860| William Thompson|    No|\n",
      "|       289|    William Scott|    No|\n",
      "|       866|     William Rice|    No|\n",
      "|        58| William Mitchell|   Yes|\n",
      "|       973|  William Jackson|   Yes|\n",
      "|       126|     William Hess|   Yes|\n",
      "|       966|   William Garcia|    No|\n",
      "|       179|    William Davis|    No|\n",
      "|       139|    William Adams|   Yes|\n",
      "|       934|   Whitney Wright|    No|\n",
      "|       893|   Wendy Thornton|   Yes|\n",
      "|       885|    Wendy Freeman|    No|\n",
      "+----------+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ej_3 = spark.sql(\"\"\"\n",
    "SELECT CustomerID, Name,\n",
    "    CASE\n",
    "        WHEN Age >= 30 THEN 'Yes'\n",
    "        WHEN Age <  30 THEN 'No'\n",
    "        ELSE 'Missing Data'\n",
    "    END AS Over30\n",
    "FROM customers\n",
    "ORDER BY Name DESC\n",
    "\"\"\")\n",
    "df_ej_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4\n",
    "\n",
    "Escriba una consulta que devuelva todas las llamadas realizadas a clientes de la profesión de ingeniería y muestre si son mayores o menores de 30, así como si terminaron comprando el producto de esa llamada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+-----------+------+\n",
      "|CallID|CustomerID|           Name|ProductSold|Over30|\n",
      "+------+----------+---------------+-----------+------+\n",
      "|  3688|       699|  Willie Greene|          0|   Yes|\n",
      "|  1552|       699|  Willie Greene|          1|   Yes|\n",
      "|  1817|       699|  Willie Greene|          0|   Yes|\n",
      "|  6270|       699|  Willie Greene|          0|   Yes|\n",
      "|  4150|       699|  Willie Greene|          0|   Yes|\n",
      "|  4900|       699|  Willie Greene|          1|   Yes|\n",
      "|  5305|       699|  Willie Greene|          1|   Yes|\n",
      "|  6191|       699|  Willie Greene|          0|   Yes|\n",
      "|  9705|       699|  Willie Greene|          0|   Yes|\n",
      "|  9714|       699|  Willie Greene|          0|   Yes|\n",
      "|  9844|       699|  Willie Greene|          0|   Yes|\n",
      "|  1158|       973|William Jackson|          0|   Yes|\n",
      "|  1516|       973|William Jackson|          0|   Yes|\n",
      "|  1944|       973|William Jackson|          0|   Yes|\n",
      "|  3026|       973|William Jackson|          0|   Yes|\n",
      "|  3113|       973|William Jackson|          0|   Yes|\n",
      "|  3162|       973|William Jackson|          0|   Yes|\n",
      "|   827|       973|William Jackson|          0|   Yes|\n",
      "|  3780|       973|William Jackson|          1|   Yes|\n",
      "|  5100|       973|William Jackson|          0|   Yes|\n",
      "+------+----------+---------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ej_4 = spark.sql(\"\"\"\n",
    "SELECT CallID, Cu.CustomerID, Name, ProductSold,\n",
    "    CASE\n",
    "        WHEN Age >= 30 THEN 'Yes'\n",
    "        WHEN Age <  30 THEN 'No'\n",
    "        ELSE 'Missing Data'\n",
    "    END AS Over30\n",
    "FROM customers Cu\n",
    "JOIN calls Ca ON Ca.CustomerID = Cu.CustomerID\n",
    "WHERE Occupation LIKE '%Engineer%'\n",
    "ORDER BY Name DESC\n",
    "\"\"\")\n",
    "df_ej_4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 5\n",
    "\n",
    "Escriba dos consultas: una que calcule las ventas totales y las llamadas totales realizadas a los clientes de la profesión de ingeniería y otra que calcule las mismas métricas para toda la base de clientes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|TotalSales|NCalls|\n",
      "+----------+------+\n",
      "|       502|  2483|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ej_5 = spark.sql(\"\"\"\n",
    "SELECT SUM(ProductSold) AS TotalSales, COUNT(*) AS NCalls\n",
    "FROM customers Cu\n",
    "JOIN calls Ca ON Ca.CustomerID = Cu.CustomerID\n",
    "WHERE Occupation LIKE '%Engineer%'\n",
    "\"\"\")\n",
    "df_ej_5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 6\n",
    "\n",
    "Escriba una consulta que devuelva, para cada agente, el nombre del agente, la cantidad de llamadas, las llamadas más largas y más cortas, la duración promedio de las llamadas y la cantidad total de productos vendidos. Nombra las columnas AgentName, NCalls, Shortest, Longest, AvgDuration y TotalSales.\n",
    "\n",
    "Luego ordena la tabla por AgentName en orden alfabético. (Asegúrese de incluir la cláusula WHERE PickedUp = 1 para calcular solo el promedio de todas las llamadas que fueron atendidas (de lo contrario, ¡todas las duraciones mínimas serán 0)!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+--------+-------+-----------+----------+\n",
      "|         AgentName|NCalls|Shortest|Longest|AvgDuration|TotalSales|\n",
      "+------------------+------+--------+-------+-----------+----------+\n",
      "|           Agent X|   640|      22|    334|     180.98|       194|\n",
      "|      Angel Briggs|   591|      12|    362|     181.08|       157|\n",
      "|Christopher Moreno|   649|      47|    363|     177.98|       189|\n",
      "|        Dana Hardy|   554|      49|    356|      177.2|       182|\n",
      "|      Gloria Singh|   662|      36|    349|     182.18|       209|\n",
      "|    Jocelyn Parker|   621|      40|    336|     180.33|       184|\n",
      "|      Lisa Cordova|   639|      46|    344|     179.21|       201|\n",
      "|  Michele Williams|   685|      22|    306|     177.88|       198|\n",
      "|        Paul Nunez|   648|      -5|    323|     181.07|       194|\n",
      "|       Randy Moore|   600|      16|    326|      178.6|       177|\n",
      "|       Todd Morrow|   631|      -3|    339|     180.71|       204|\n",
      "+------------------+------+--------+-------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ej_6 = spark.sql(\"\"\"\n",
    "SELECT Name AS AgentName, COUNT(*) AS NCalls, MIN(Duration) AS Shortest, MAX(Duration) AS Longest, ROUND(AVG(Duration),2) AS AvgDuration, SUM(ProductSold) AS TotalSales\n",
    "FROM calls C\n",
    "    JOIN agents A ON C.AgentID = A.AgentID\n",
    "WHERE PickeDup = 1\n",
    "GROUP BY Name\n",
    "ORDER BY Name\n",
    "\"\"\")\n",
    "df_ej_6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 7\n",
    "\n",
    "Dos métricas del desempeño de los agentes de ventas que le interesan a su empresa son:\n",
    "\n",
    "1. para cada agente, cuántos segundos en promedio les toma vender un producto cuando tienen éxito\n",
    "2. para cada agente, cuántos segundos en promedio permanecen en el teléfono antes de darse por vencidos cuando no tienen éxito. Escribe una consulta que calcule esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+\n",
      "|              name|    avgWhenNotSold|       avgWhenSold|\n",
      "+------------------+------------------+------------------+\n",
      "|           Agent X|109.81705639614856|             185.5|\n",
      "|      Angel Briggs|108.66160220994475|180.56050955414014|\n",
      "|Christopher Moreno| 112.4882108183079|182.03703703703704|\n",
      "|        Dana Hardy| 97.73082706766917|182.30769230769232|\n",
      "|      Gloria Singh|115.41143654114366|181.10047846889952|\n",
      "|    Jocelyn Parker|118.99848484848485| 181.7608695652174|\n",
      "|      Lisa Cordova|110.09470752089136|176.46766169154228|\n",
      "|  Michele Williams|111.77763496143959|176.18686868686868|\n",
      "|        Paul Nunez|113.24380165289256| 181.0257731958763|\n",
      "|       Randy Moore|107.28611898016997|177.47457627118644|\n",
      "|       Todd Morrow|109.15677966101696|180.12745098039215|\n",
      "+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ej_7 = spark.sql(\"\"\"\n",
    "SELECT a.name,\n",
    "SUM(\n",
    "   CASE\n",
    "       WHEN productsold = 0 THEN duration\n",
    "       ELSE 0\n",
    "   END)/SUM(\n",
    "   CASE\n",
    "       WHEN productsold = 0 THEN 1\n",
    "       ELSE 0\n",
    "   END)\n",
    "AS avgWhenNotSold ,\n",
    "SUM(\n",
    "   CASE\n",
    "       WHEN productsold = 1 THEN duration\n",
    "       ELSE 0\n",
    "   END)/SUM(\n",
    "       CASE WHEN productsold = 1 THEN 1\n",
    "       ELSE 0\n",
    "   END)\n",
    "AS avgWhenSold\n",
    "FROM calls c\n",
    "JOIN agents a ON c.agentid = a.agentid\n",
    "GROUP BY a.name\n",
    "ORDER BY 1\n",
    "\"\"\")\n",
    "df_ej_7.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
